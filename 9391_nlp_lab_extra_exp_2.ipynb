{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### MOHIT SUNIL PANSARE\n",
        "### 9391, BE AI-DS\n",
        "### NLP, EXTRA EXPERIMENT 2"
      ],
      "metadata": {
        "id": "5hRObu64wEfQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import treebank\n",
        "import re"
      ],
      "metadata": {
        "id": "WtA1zlmTq185"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the Penn Treebank dataset (if not already downloaded)\n",
        "nltk.download('treebank')\n",
        "\n",
        "# Load the Penn Treebank dataset\n",
        "sentences = treebank.sents()\n",
        "tagged_sentences = treebank.tagged_sents()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-v_ZA63q36p",
        "outputId": "9dc9d48a-b782-4c75-8cfc-aed49f350813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define an initial tagging (baseline tags)\n",
        "baseline_tags = [' '.join([tag for word, tag in sentence]) for sentence in tagged_sentences]"
      ],
      "metadata": {
        "id": "cAkRWkFEq8Jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformation rules (sample rules for demonstration)\n",
        "rules = [\n",
        "    (r'won\\'t', 'VB', 'MD'),       # Transform \"won't\" from VB to MD\n",
        "    (r'^.*ould$', 'NN', 'MD'),     # Transform words ending in \"ould\" from NN to MD\n",
        "    (r'^.*ing$', 'NN', 'VBG'),     # Transform words ending in \"ing\" from NN to VBG\n",
        "    (r'^[A-Z].*', 'NNP', 'NN'),    # Transform words starting with a capital letter from NNP to NN\n",
        "]"
      ],
      "metadata": {
        "id": "ugu5jpdlq9hH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply transformation rules to improve tagging\n",
        "def apply_rules(tagged_sentence, rules):\n",
        "    for rule in rules:\n",
        "        tagged_sentence = re.sub(rule[0], f'{rule[2]}', tagged_sentence)\n",
        "    return tagged_sentence"
      ],
      "metadata": {
        "id": "RaXHOwpurB9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Improve tagging based on transformation rules for a subset of sentences\n",
        "for i in range(3):  # Applying rules to the first 10 sentences for demonstration\n",
        "    improved_tags = apply_rules(baseline_tags[i], rules)\n",
        "    print(f\"Sentence: {' '.join([word for word in sentences[i]])}\")\n",
        "    print(f\"Baseline tags: {baseline_tags[i]}\")\n",
        "    print(f\"Improved Tags: {improved_tags}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7p2fg1NpdpQ",
        "outputId": "c52be62b-f0fa-4d71-f006-a071c2dd705d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: Pierre Vinken , 61 years old , will join the board as a nonexecutive director Nov. 29 .\n",
            "Baseline tags: NNP NNP , CD NNS JJ , MD VB DT NN IN DT JJ NN NNP CD .\n",
            "Improved Tags: NN\n",
            "\n",
            "Sentence: Mr. Vinken is chairman of Elsevier N.V. , the Dutch publishing group .\n",
            "Baseline tags: NNP NNP VBZ NN IN NNP NNP , DT NNP VBG NN .\n",
            "Improved Tags: NN\n",
            "\n",
            "Sentence: Rudolph Agnew , 55 years old and former chairman of Consolidated Gold Fields PLC , was named *-1 a nonexecutive director of this British industrial conglomerate .\n",
            "Baseline tags: NNP NNP , CD NNS JJ CC JJ NN IN NNP NNP NNP NNP , VBD VBN -NONE- DT JJ NN IN DT JJ JJ NN .\n",
            "Improved Tags: NN\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Sentence: Pierre Vinken , 61 years old , will join the board as a nonexecutive director Nov. 29 .\n",
        "\n",
        "# Original Tags (Baseline Tags): NNP NNP , CD NNS JJ , MD VB DT NN IN DT JJ NN NNP CD .\n",
        "# Improved Tags: NN\n",
        "# Explanation:\n",
        "# In this sentence, the transformation rules were applied to correct the part-of-speech tags.\n",
        "# For example, \"Pierre\" and \"Vinken\" were initially tagged as proper nouns (NNP),\n",
        "# but the transformation rule likely changed them to a more general noun (NN)."
      ],
      "metadata": {
        "id": "Y5nYPQGcqfcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# WITH LIBRARIES"
      ],
      "metadata": {
        "id": "VdSyfvXivBeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "02tw-xTSvJXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK resources (if not already downloaded)\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-01aTuckvMC2",
        "outputId": "aeec21fc-ca44-45e8-e1d5-7d0560ae70e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentence to be processed\n",
        "sentence = \"I wish I could have a pizza right now.\"\n",
        "\n",
        "# Tokenization\n",
        "tokens = nltk.word_tokenize(sentence)\n",
        "print(f\"Tokens: {tokens}\")\n",
        "\n",
        "# Part-of-Speech Tagging\n",
        "pos_tags = nltk.pos_tag(tokens)\n",
        "print(f\"pos_tags: {pos_tags}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJoxYUPCvN6y",
        "outputId": "378f03d2-7476-40f6-f1f7-f3d07b2db8f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['I', 'wish', 'I', 'could', 'have', 'a', 'pizza', 'right', 'now', '.']\n",
            "pos_tags: [('I', 'PRP'), ('wish', 'VBP'), ('I', 'PRP'), ('could', 'MD'), ('have', 'VB'), ('a', 'DT'), ('pizza', 'NN'), ('right', 'RB'), ('now', 'RB'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentiment Analysis\n",
        "analysis = TextBlob(sentence)\n",
        "polarity = analysis.sentiment.polarity\n",
        "subjectivity = analysis.sentiment.subjectivity\n"
      ],
      "metadata": {
        "id": "NRPP4k9zr9ZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original Sentence:\", sentence)\n",
        "print(\"Tokenization:\", tokens)\n",
        "print(\"Part-of-Speech Tags:\", pos_tags)\n",
        "print(\"Sentiment Analysis - Polarity:\", polarity)\n",
        "print(\"Sentiment Analysis - Subjectivity:\", subjectivity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvXxmUMpubuI",
        "outputId": "4beb1613-2949-4306-8a19-afa61ae70fb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Sentence: I wish I could have a pizza right now.\n",
            "Tokenization: ['I', 'wish', 'I', 'could', 'have', 'a', 'pizza', 'right', 'now', '.']\n",
            "Part-of-Speech Tags: [('I', 'PRP'), ('wish', 'VBP'), ('I', 'PRP'), ('could', 'MD'), ('have', 'VB'), ('a', 'DT'), ('pizza', 'NN'), ('right', 'RB'), ('now', 'RB'), ('.', '.')]\n",
            "Sentiment Analysis - Polarity: 0.2857142857142857\n",
            "Sentiment Analysis - Subjectivity: 0.5357142857142857\n"
          ]
        }
      ]
    }
  ]
}