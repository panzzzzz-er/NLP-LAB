{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLc1lIbPRJeL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1824295-6ca8-458a-8151-a100d93123a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCNA8QBtPRzZ"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.corpus import indian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jkGrfypPiei",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a29c9c5f-f8e1-4e65-adae-5cd1452ca085"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    The sun was setting behind the mountains, casting a warm golden glow across the landscape.\n",
            "    Birds were chirping in the trees as they settled down for the night.\n",
            "    A gentle breeze rustled the leaves, creating a soothing melody.\n",
            "    People were taking their evening strolls, enjoying the tranquility of the moment.\n",
            "    The stars began to twinkle in the darkening sky.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "# english_paragraph = input(\"Enter a small paragraph in English: \")\n",
        "english_paragraph = '''\n",
        "    The sun was setting behind the mountains, casting a warm golden glow across the landscape.\n",
        "    Birds were chirping in the trees as they settled down for the night.\n",
        "    A gentle breeze rustled the leaves, creating a soothing melody.\n",
        "    People were taking their evening strolls, enjoying the tranquility of the moment.\n",
        "    The stars began to twinkle in the darkening sky.\n",
        "  '''\n",
        "print(english_paragraph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NR3F6Cczifmi"
      },
      "outputs": [],
      "source": [
        "def scratch_pos_tag(words):\n",
        "    tagged_sentence = []\n",
        "\n",
        "    for word in words:\n",
        "        if word.endswith(\"ing\"):\n",
        "            tagged_sentence.append((word, \"VBG\"))  # Verb, Gerund/Present Participle\n",
        "        elif word.endswith(\"ed\"):\n",
        "            tagged_sentence.append((word, \"VBD\"))  # Verb, Past Tense\n",
        "        elif word.isnumeric():\n",
        "            tagged_sentence.append((word, \"CD\"))   # Cardinal Number\n",
        "        elif word.lower() in [\"a\", \"an\", \"the\"]:\n",
        "            tagged_sentence.append((word, \"DT\"))   # Determiner (Article)\n",
        "        else:\n",
        "            tagged_sentence.append((word, \"X\"))    # Noun, singular or mass (default)\n",
        "\n",
        "    return tagged_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_j8-tAIPQ-zk"
      },
      "outputs": [],
      "source": [
        "words = word_tokenize(english_paragraph)\n",
        "tagged_words = scratch_pos_tag(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xuYz06qiocL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "519dae29-4aea-4692-f290-fd5d29e25401"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The/DT\n",
            "sun/X\n",
            "was/X\n",
            "setting/VBG\n",
            "behind/X\n",
            "the/DT\n",
            "mountains/X\n",
            ",/X\n",
            "casting/VBG\n",
            "a/DT\n",
            "warm/X\n",
            "golden/X\n",
            "glow/X\n",
            "across/X\n",
            "the/DT\n",
            "landscape/X\n",
            "./X\n",
            "Birds/X\n",
            "were/X\n",
            "chirping/VBG\n",
            "in/X\n",
            "the/DT\n",
            "trees/X\n",
            "as/X\n",
            "they/X\n",
            "settled/VBD\n",
            "down/X\n",
            "for/X\n",
            "the/DT\n",
            "night/X\n",
            "./X\n",
            "A/DT\n",
            "gentle/X\n",
            "breeze/X\n",
            "rustled/VBD\n",
            "the/DT\n",
            "leaves/X\n",
            ",/X\n",
            "creating/VBG\n",
            "a/DT\n",
            "soothing/VBG\n",
            "melody/X\n",
            "./X\n",
            "People/X\n",
            "were/X\n",
            "taking/VBG\n",
            "their/X\n",
            "evening/VBG\n",
            "strolls/X\n",
            ",/X\n",
            "enjoying/VBG\n",
            "the/DT\n",
            "tranquility/X\n",
            "of/X\n",
            "the/DT\n",
            "moment/X\n",
            "./X\n",
            "The/DT\n",
            "stars/X\n",
            "began/X\n",
            "to/X\n",
            "twinkle/X\n",
            "in/X\n",
            "the/DT\n",
            "darkening/VBG\n",
            "sky/X\n",
            "./X\n"
          ]
        }
      ],
      "source": [
        "for word, pos in tagged_words:\n",
        "    print(f\"{word}/{pos}\")\n",
        "    # print(f\"{word}/{pos}\", end=\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8m9yZhHRBbG"
      },
      "outputs": [],
      "source": [
        "stat_tagged_words = nltk.pos_tag(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCsaIu_JRewg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "eb68ba71-52b7-4eb7-82ff-1962d4192ffc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-bcee585594d5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstat_nouns_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstat_verbs_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_nouns_verbs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstat_tagged_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Statistical POS Tagging:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of nouns (statistical):\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstat_nouns_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of verbs (statistical):\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstat_verbs_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'count_nouns_verbs' is not defined"
          ]
        }
      ],
      "source": [
        "stat_nouns_count, stat_verbs_count = count_nouns_verbs(stat_tagged_words)\n",
        "print(\"Statistical POS Tagging:\")\n",
        "print(\"Number of nouns (statistical):\", stat_nouns_count)\n",
        "print(\"Number of verbs (statistical):\", stat_verbs_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dS0coa4CeEqm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c596200-53a1-414b-8000-fc767da9ea07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stanfordnlp\n",
            "  Downloading stanfordnlp-0.2.0-py3-none-any.whl (158 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/158.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m122.9/158.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from stanfordnlp) (1.23.5)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from stanfordnlp) (3.20.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from stanfordnlp) (2.31.0)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from stanfordnlp) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stanfordnlp) (4.66.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->stanfordnlp) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->stanfordnlp) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->stanfordnlp) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->stanfordnlp) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->stanfordnlp) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->stanfordnlp) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.0.0->stanfordnlp) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.0.0->stanfordnlp) (16.0.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->stanfordnlp) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->stanfordnlp) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->stanfordnlp) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->stanfordnlp) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->stanfordnlp) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->stanfordnlp) (1.3.0)\n",
            "Installing collected packages: stanfordnlp\n",
            "Successfully installed stanfordnlp-0.2.0\n"
          ]
        }
      ],
      "source": [
        "! pip install stanfordnlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHYpT1aggmZ0",
        "outputId": "8a039c6e-80af-474d-de61-55287b9d310e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using the default treebank \"hi_hdtb\" for language \"hi\".\n",
            "Would you like to download the models for: hi_hdtb now? (Y/n)\n",
            "Y\n",
            "\n",
            "Default download directory: /root/stanfordnlp_resources\n",
            "Hit enter to continue or type an alternate directory.\n",
            "\n",
            "\n",
            "Downloading models for: hi_hdtb\n",
            "Download location: /root/stanfordnlp_resources/hi_hdtb_models.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 208M/208M [00:36<00:00, 5.71MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Download complete.  Models saved to: /root/stanfordnlp_resources/hi_hdtb_models.zip\n",
            "Extracting models file for: hi_hdtb\n",
            "Cleaning up...Done.\n"
          ]
        }
      ],
      "source": [
        "import stanfordnlp\n",
        "\n",
        "# Download the Hindi language model (only needed once)\n",
        "stanfordnlp.download('hi')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jngRlhFYdkAw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e53d8e09-13d5-48ca-de22-09e1bb503254"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use device: cpu\n",
            "---\n",
            "Loading: tokenize\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/hi_hdtb_models/hi_hdtb_tokenizer.pt', 'lang': 'hi', 'shorthand': 'hi_hdtb', 'mode': 'predict'}\n",
            "---\n",
            "Loading: pos\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/hi_hdtb_models/hi_hdtb_tagger.pt', 'pretrain_path': '/root/stanfordnlp_resources/hi_hdtb_models/hi_hdtb.pretrain.pt', 'lang': 'hi', 'shorthand': 'hi_hdtb', 'mode': 'predict'}\n",
            "---\n",
            "Loading: lemma\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/hi_hdtb_models/hi_hdtb_lemmatizer.pt', 'lang': 'hi', 'shorthand': 'hi_hdtb', 'mode': 'predict'}\n",
            "Building an attentional Seq2Seq model...\n",
            "Using a Bi-LSTM encoder\n",
            "Using soft attention for LSTM.\n",
            "Finetune all embeddings.\n",
            "[Running seq2seq lemmatizer with edit classifier]\n",
            "---\n",
            "Loading: depparse\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/hi_hdtb_models/hi_hdtb_parser.pt', 'pretrain_path': '/root/stanfordnlp_resources/hi_hdtb_models/hi_hdtb.pretrain.pt', 'lang': 'hi', 'shorthand': 'hi_hdtb', 'mode': 'predict'}\n",
            "Done loading processors!\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stanfordnlp/models/depparse/model.py:157: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at ../aten/src/ATen/native/TensorAdvancedIndexing.cpp:1772.)\n",
            "  unlabeled_scores.masked_fill_(diag, -float('inf'))\n"
          ]
        }
      ],
      "source": [
        "# Load the Hindi language model\n",
        "nlp = stanfordnlp.Pipeline(lang='hi')\n",
        "\n",
        "# Example Hindi paragraph\n",
        "hindi_paragraph = \"वर्षा के मौसम में बरसात होती है। बच्चे खुशी से खेलते हैं।\"\n",
        "\n",
        "# Process the paragraph with stanfordnlp\n",
        "doc = nlp(hindi_paragraph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FDNIdb0d56w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a95d7215-718e-4af8-d9ed-80dd56581dcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "वर्षा NOUN\n",
            "के ADP\n",
            "मौसम NOUN\n",
            "में ADP\n",
            "बरसात NOUN\n",
            "होती VERB\n",
            "है AUX\n",
            "। PUNCT\n",
            "बच्चे NOUN\n",
            "खुशी NOUN\n",
            "से ADP\n",
            "खेलते VERB\n",
            "हैं AUX\n",
            "। PUNCT\n"
          ]
        }
      ],
      "source": [
        "# Access POS tags from the processed document\n",
        "for sentence in doc.sentences:\n",
        "    for word in sentence.words:\n",
        "        print(word.text, word.upos)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_mrUo0SO9P4g"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}